title: kafka在zk中的目录结构
date: 2018/09/20 15:30:00
tags:
- kafka
categories:
- kafka

---

### kafka在zk中的目录结构

![kafka-in-zk](/img/kafka/kafka-in-zk.png)

#### /brokers

当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息

##### /brokers/ids

每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复)，此节点为临时znode(EPHEMERAL)

<!--more-->

```
> ls /brokers/ids/101
[101, 102, 103]

> get /brokers/ids/101
{
	"listener_security_protocol_map":{"PLAINTEXT":"PLAINTEXT"},
	"endpoints":["PLAINTEXT://node104.kafka.bigdata.dmp.com:9092"],
	"jmx_port":8999,		//jmx端口号
	"host":"node104.kafka.bigdata.dmp.com",  //主机名或ip地址
	"timestamp":"1537425599417",  //broker初始启动时的时间戳
	"port":9092,   //broker的服务端端口号，由server.properties中参数port确定
	"version":4    //版本编号默认为1
}
cZxid = 0x7183581d4
ctime = Thu Sep 20 14:39:59 CST 2018
mZxid = 0x7183581d4
mtime = Thu Sep 20 14:39:59 CST 2018
pZxid = 0x7183581d4
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x36324802b64f5d0
dataLength = 230
numChildren = 0

```


##### /brokers/topics

包含各topic的partition状态信息

```
> ls /brokers/topics  
[pv-event, pv-event-nginx-log, gdt-request, leopard-module-stats-app, wolves-event, ad-track-nginx-log, ...]

> ls /brokers/topics/pv-event-nginx-log
[partitions]

> get /brokers/topics/pv-event-nginx-log
{
	"version":1,
	"partitions":
		{
			"8":[103,101,102],  //同步副本组brokerId列表(ISR)
			"4":[102,101,103],"11":[103,102,101],"9":[101,103,102],"5":[103,102,101],"10":[102,101,103],"6":[101,102,103],"1":[102,103,101],"0":[101,102,103],"2":[103,101,102],"7":[102,103,101],"3":[101,103,102]
		}
}
cZxid = 0x200000143
ctime = Thu Oct 12 16:07:33 CST 2017
mZxid = 0x71306a4ee
mtime = Sun Aug 26 03:25:57 CST 2018
pZxid = 0x200000146
cversion = 1
dataVersion = 13843
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 246
numChildren = 1

> ls /brokers/topics/pv-event-nginx-log/partitions
[0, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

> ls /brokers/topics/pv-event-nginx-log/partitions/0
[state]

> get /brokers/topics/pv-event-nginx-log/partitions/0/state
{
	"controller_epoch":28,	//表示kafka集群中的中央控制器选举次数
	"leader":101,			//该partition选举leader的brokerId
	"version":1,			//版本编号默认为1,
	"leader_epoch":382,		//该partition leader选举次数
	"isr":[101,103,102]     //[同步副本组brokerId列表]
}
cZxid = 0x200000154
ctime = Thu Oct 12 16:07:33 CST 2017
mZxid = 0x7183c9936
mtime = Thu Sep 20 17:49:19 CST 2018
pZxid = 0x200000154
cversion = 0
dataVersion = 1426
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 87
numChildren = 0

```

##### /brokers/seqid

该目录的作用是帮助kafka自动生成broker.id的。

自动生成broker.id的原理是先往/brokers/seqid节点中写入一个空字符串，然后获取返回的Stat信息中的version的值，然后将version的值和reserved.broker.max.id参数配置的值相加可得。之所以是先往节点中写入数据再获取Stat信息，这样可以确保返回的version值大于0，进而就可以确保生成的broker.id值大于reserved.broker.max.id参数配置的值，符合非自动生成的broker.id的值在[0, reserved.broker.max.id]区间的设定。

```
> get /brokers/seqid
null
cZxid = 0x20000000f
ctime = Thu Oct 12 15:35:21 CST 2017
mZxid = 0x20000000f
mtime = Thu Oct 12 15:35:21 CST 2017
pZxid = 0x20000000f
cversion = 0
dataVersion = 0  //基于此version的值
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 0
numChildren = 0
```

#### /consumers

每个consumer都有一个唯一的ID，此id用来标记消费者信息.

该目录下仅展示使用zk进行消费的consumers，如果之间指定kafka节点进行消费，不会在此展示

##### /consumers/{groupId}/ids

```
> ls /consumers
[console-consumer-84155, console-consumer-32194, wolves_report, console-consumer-9761, wolves_v2_gdt, console-consumer-63530, wolves, wolves_feedback, wolves_kuaishou, console-consumer-62629, ftrl1, console-consumer-56068, wolves_tuia]

> ls /consumers/wolves_report
[ids, owners, offsets]

> ls /consumers/wolves_report/ids
[wolves_report_node1.tc.wolves.dmp.com-1536837975646-39504764, wolves_report_node1.tc.wolves.dmp.com-1536838003051-182cc752,...]

> get /consumers/wolves_report/ids/wolves_report_node1.tc.wolves.dmp.com-1536837975646-39504764
{
	"version":1,   //版本编号，默认为1
	"subscription":	//订阅topic列表
		{
			"wolves-event":3		//consumer中topic消费者线程数
		},
	"pattern":"static",
	"timestamp":"1537128878487"  //consumer启动时的时间戳
}
cZxid = 0x717782b21
ctime = Mon Sep 17 04:14:38 CST 2018
mZxid = 0x717782b21
mtime = Mon Sep 17 04:14:38 CST 2018
pZxid = 0x717782b21
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x36324802b64ea62
dataLength = 94
numChildren = 0

```

##### /consumers/{groupId}/owner

```
> ls /consumers/wolves_report/owners                                                           
[wolves-event]   // topic

> ls /consumers/wolves_report/owners/wolves-event
[0, 1, 2]		// partitionId

> get /consumers/wolves_report/owners/wolves-event/0
wolves_report_node1.tc.wolves.dmp.com-1536837527210-1310d8f9-0
cZxid = 0x717782ba9
ctime = Mon Sep 17 04:14:40 CST 2018
mZxid = 0x717782ba9
mtime = Mon Sep 17 04:14:40 CST 2018
pZxid = 0x717782ba9
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x26324802b69ea62
dataLength = 62
numChildren = 0

```

##### /consumers/{groupId}/offset

用来跟踪每个consumer目前所消费的partition中最大的offset

```
> ls /consumers/wolves_report/offsets               
[wolves-event] 	// topic

> ls /consumers/wolves_report/offsets/wolves-event
[0, 1, 2] 	// partitionId

> get /consumers/wolves_report/offsets/wolves-event/0
48800
cZxid = 0x200e97e36
ctime = Thu Nov 23 17:22:10 CST 2017
mZxid = 0x718665858
mtime = Fri Sep 21 12:02:39 CST 2018
pZxid = 0x200e97e36
cversion = 0
dataVersion = 11910567
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0

```

#### /admin

##### /admin/reassign_partitions

用以partitions重分区，reassign结束后会删除该目录

```
> ls /admin/reassign_partitions
[]
```

##### /admin/preferred_replica_election

用以partitions各副本leader选举，replica election结束后会删除该目录

```
> ls /admin/reassign_partitions
[]
```

##### /admin/delete_topics

管理已删除的topics，broker启动时检查并确保存在

```
> ls /admin/delete_topics
[]
```

#### /controller

存储center controller中央控制器所在kafka broker的信息

```
> get /controller
{
	"version":1,		//版本编号默认为1
	"brokerid":101,		//broker唯一编号
	"timestamp":"1537425633921"	//broker中央控制器变更时的时间戳
}
cZxid = 0x7183583bd
ctime = Thu Sep 20 14:40:33 CST 2018
mZxid = 0x7183583bd
mtime = Thu Sep 20 14:40:33 CST 2018
pZxid = 0x7183583bd
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x36324802b64f5d0
dataLength = 56
numChildren = 0
```

#### /controller_epoch

此值为一个数字,kafka集群中第一个broker第一次启动时为1，以后只要集群中center controller中央控制器所在broker变更或挂掉，就会重新选举新的center controller，每次center controller变更controller_epoch值就会 + 1; 

```
> get /controller_epoch
28
cZxid = 0x200000017
ctime = Thu Oct 12 15:35:21 CST 2017
mZxid = 0x7183583be
mtime = Thu Sep 20 14:40:33 CST 2018
pZxid = 0x200000017
cversion = 0
dataVersion = 27
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 2
numChildren = 0
```

#### /config

- /config/changes  broker启动时检查并确保存在，所有broker全程监控child change
- /config/clients  broker启动时检查并确保存在
- /config/topics   broker启动时检查并确保存在


### zookeeper操作命令

在确保zookeeper服务启动状态下，通过 bin/zkCli.sh -server xxx:2181 连接

```
1. 显示根目录下、文件： ls /  使用 ls 命令来查看当前 ZooKeeper 中所包含的内容
2. 显示根目录下、文件： ls2 / 查看当前节点数据并能看到更新次数等数据
3. 创建文件，并设置初始内容： create /zk "test" 创建一个新的 znode节点“ zk ”以及与它关联的字符串
4. 获取文件内容： get /zk 确认 znode 是否包含我们所创建的字符串
5. 修改文件内容： set /zk "zkbak" 对 zk 所关联的字符串进行设置
6. 删除文件： delete /zk 将刚才创建的 znode 删除
7. 退出客户端： quit
8. 帮助命令： help 
```
