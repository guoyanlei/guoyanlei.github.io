

title: Hive表跨集群迁移
date: 2018/05/22 14:30:04
tags:
- hive
- 跨集群
categories:
- hive

---

公司新建了个大数据集群，需对老集群上的hive表数据迁移到新的集群中。这里总结下整个Hive表迁移的过程。

<!--more-->


### 创建数据临时目录


```
hdfs dfs -mkdir /tmp/hive-export

```

### 生成数据导出脚本

```
-- 该命令会生成所有表的导出脚本
hive -e "show tables" | awk '{printf "export table %s to @/tmp/hive-export/%s@;\n",$1,$1}' | sed "s/@/'/g" > export.sql

-- 若只想导出某个，可在hive中单独执行
export table ods_log_event_base_data_orc_hh to '/tmp/hive-export/ods_log_event_base_data_orc_hh';

在运行前，需要将hadoop-distcp-2.5.0-cdh5.3.3.jar 拷贝到hive的lib中，否则会报错（Cannot find DistCp class package: org.apache.hadoop.tools.DistCp）
cp /data/dmp/hadoop/share/hadoop/tools/lib/hadoop-distcp-2.5.0-cdh5.3.3.jar /data/dmp/hive/lib/

```

### 手工导出数据到HDFS

```
hive -f export.sql

完成后，hdfs的导出路径上会有相关的信息：
/tmp/hive-export/ods_log_event_base_data_orc_hh
进去可看到_metadata和各分区信息

```

### 下载上传数据 or diskcp数据

下载HDFS数据到本地，并传送到目标集群（targetDir为目标集群地址）的/tmp/hive-export目录：

```
hdfs dfs -get /tmp/hive-export/
scp -r hive-export/ export.sql root@targetDir
hdfs dfs -put hive-export/ /tmp/hive-export
```

或者使用diskcp命令，通过分布式方式拷贝到目标集群

```
hadoop distcp hdfs://hadoop-dmp:8020/tmp/hive-export/ods_log_event_base_data_orc_hh hdfs://10.215.24.109:8020/tmp/hive-export/ods_log_event_base_data_orc_hh
```

### 生成数据导入脚本

```
执行如下命令，复制导出脚本，并将脚本修改为导入脚本：

cp export.sql import.sql
sed -i 's/export table/import table/g' import.sql
sed -i 's/ to / from /g' import.sql

```

### 导入数据

```
hive -f import.sql
```


