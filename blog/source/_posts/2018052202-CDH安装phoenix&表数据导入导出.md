

title: CDH安装phoenix&表数据导入导出
date: 2018/05/22 15:30:04
tags:
- phoenix
- pig
categories:
- pheonix

---

本文记录下CDH安装Phoenix所注意到事项，以及Pheonix表数据的导入导出。

<!--more-->

### cloudera manager 安装pheonix

下面总结Cloudera Manager安装并使用pheonix的步骤。

```

1. 下载pheonix-CDH版本 phoenix-4.13.2-cdh5.11.2
2. 拷贝到一个节点，并解压
3. 将phoenix-4.13.2-cdh5.11.2-server.jar 拷贝到Hbase集群的每一个Master和Region Server节点的/data/dmp/cloudera/parcels/CDH/lib/hbase/lib/
4. 重启Hbase节点
5. 建立启动脚本（./sqlline.py node1.zk.bigdata.dmp.com,node2.zk.bigdata.dmp.com,node3.zk.bigdata.dmp.com:2181:/hbase）
6. 若想在hive中通过PhoenixStorageHandler方式读取pheonix中的数据，则需将phoenix-4.13.2-cdh5.11.2-client.jar 和 phoenix-hive-4.13.2-cdh5.11.2.jar 拷贝到每个HiveServer节点的/data/dmp/cloudera/parcels/CDH/lib/hive/lib下
7. 重启HiveServer

```

### 使用Hive读写phoenix

在数据仓库Hive中最常用的场景就是将计算完的数据写入到phoenix，方便之后使用phoenix来查询。

方式就是在hive中建立与phoenix映射的外部表，建立之前需完成安装步骤中的6，7，建立完成后即可读写phoenix的数据。

```
-- phoenix外部表（hive执行）
add jar hdfs://nameservice:8020/user/udf/phoenix-4.13.2-cdh5.11.2-hive.jar;
CREATE EXTERNAL TABLE dws_phoenix_log_project_table_id(
    m_item_id     string,
    app_key       string,
    project       string,
    p_table       string,
    stat_date     string,
    t_module      string
)
STORED BY  "org.apache.phoenix.hive.PhoenixStorageHandler"
TBLPROPERTIES(
    "phoenix.table.name" = "DWS_PHOENIX_DMP_LOG_PROJECT_TABLE_ID",
    "phoenix.zookeeper.quorum" = "node1.zk.bigdata.dmp.com,node2.zk.bigdata.dmp.com,node3.zk.bigdata.dmp.com",
    "phoenix.zookeeper.znode.parent" = "/hbase",
    "phoenix.zookeeper.client.port" = "2181",
    "phoenix.rowkeys" = "M_ITEM_ID,APP_KEY,PROJECT,P_TABLE,STAT_DATE",
    "phoenix.column.mapping" = "m_item_id:M_ITEM_ID,app_key:APP_KEY,project:PROJECT,p_table:P_TABLE,stat_date:STAT_DATE,t_module:T_MODULE"
);

```

### 使用Pig将phoenix表数据批量导出

Phoenix提供了BulkLoad工具，使得用户可以将大数据量的csv格式数据高效地通过phoenix导入hbase
，那么phoenix是否也存在高效导出csv数据的工具类呢？

幸运的是phoenix官方确实提供了一个高效的导出工具类，但是必须依赖于pig。

官方文档：https://phoenix.apache.org/pig_integration.html

Pig是SQL-like语言，是在MapReduce上构建的一种高级查询语言，把一些运算编译进MapReduce模型的Map和Reduce中，并且用户可以定义自己的功能。

Cloudera Manager默认安装pig，可在集群任意节点启动pig客户端。

```
运行
- pig
- pig -x mapreduce
```

下面给出一个批量导出phoenix表数据的Pig脚本

```
REGISTER /data/dmp/phoenix/phoenix-4.13.2-cdh5.11.2-client.jar
rows = load 'hbase://table/DWS_PHOENIX_DMP_LOG_PROJECT_TABLE_ID' USING org.apache.phoenix.pig.PhoenixHBaseLoader('node1.zk.bigdata.dmp.com,node2.zk.bigdata.dmp.com,node3.zk.bigdata.dmp.com'); 
STORE rows INTO '/user/hive/warehouse/test.db/dws_phoenix_log_project_table_id' USING PigStorage(',');

默认的导出路径是保存在HDFS中的，之后可以建立Hive外部表读取文件中的数据

# 还可以批量导出部分字段
A = load 'hbase://table/DWS_PHOENIX_DMP_LOG_PROJECT_TABLE_ID/APP_KEY,PROJECT' using org.apache.phoenix.pig.PhoenixHBaseLoader('xxx');

# 也可以批量某一SQL的数据
A = load 'hbase://query/SELECT ID,NAME FROM DWS_PHOENIX_DMP_LOG_PROJECT_TABLE_ID WHERE APP_KEY = 111' using org.apache.phoenix.pig.PhoenixHBaseLoader('xxx');

- Only a SELECT query is allowed. No DML statements such as UPSERT or DELETE.
- The query may not contain any GROUP BY, ORDER BY, LIMIT, or DISTINCT clauses.
- The query may not contain any AGGREGATE functions.

```


